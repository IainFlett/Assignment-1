{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea162d49-c4e8-4b9d-9bd3-037622332336",
   "metadata": {},
   "source": [
    "# **Assignment 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e735c-c570-4ac0-ac6d-37877e705b3c",
   "metadata": {},
   "source": [
    "|  Name | Student ID | Section Contributed | Section Edited | Other Contributions |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Dueck, Ellie | 301462367 | Word Freq, Named entities, Reflection | all | Notebook Formatting,\n",
    "| Flett, Iain | 301581520 | Data Collection, Tokens, Lexical Diversity | all| Notebook Creation, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2443e65-ffbe-4e47-8d0b-14fcd0d35519",
   "metadata": {},
   "source": [
    "**references**\n",
    "<br>\n",
    "Meditations: https://www.gutenberg.org/cache/epub/2680/pg2680.txt\n",
    "<br>\n",
    "Star Trek: https://www.scifiscripts.com/scripts/startrek2_wrathofkhan.txt\n",
    "<br>\n",
    "Winnie the Pooh: https://www.gutenberg.org/cache/epub/67098/pg67098.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87c3494f-f1e2-498a-a42e-024bcf5517a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import numpy\n",
    "import re\n",
    "import matplotlib\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import FreqDist\n",
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98986443-cf3f-4983-80c0-17188ef42503",
   "metadata": {},
   "source": [
    "### **Length and Lexical Diversity:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b34737f8-66ca-4f70-8d0a-02beb497e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_info(text):\n",
    "    \"\"\"\n",
    "    Uses NLTK to calculate: tokens, types, lexical diversity\n",
    "    \n",
    "    Args:\n",
    "        text (str): a string containing the file or text\n",
    "        \n",
    "    Returns: \n",
    "        dict: a dictionary containing tokens, types, and lexical diversity\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    n_tokens = len(tokens)\n",
    "    n_types = len(set(tokens))\n",
    "    return {\n",
    "            'tokens': n_tokens,\n",
    "            'types': n_types,\n",
    "        }\n",
    "def process_dir(path):\n",
    "    \"\"\"\n",
    "    Reads all the files in a directory. Processes them using the 'get_text_info' function\n",
    "    \n",
    "    Args: \n",
    "        path (str): path to the directory where the files are\n",
    "        \n",
    "    Returns:\n",
    "        dict: a dictionary with file names as keys and the tokens, types, lexical diversity, as values\n",
    "    \n",
    "    \"\"\"\n",
    "    file_info = {}\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".txt\"):    \n",
    "            file_path = os.path.join(path, filename)      \n",
    "            with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "                file_info[filename] = get_text_info(text)\n",
    "    return file_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2de5c49d-015b-40e0-a4e5-73d90e457def",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data'\n",
    "\n",
    "filesInfo = process_dir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6b1b0580-f712-4d1f-991e-2e1e92dd4f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Meditations_Marcus_Aurelius.txt</th>\n",
       "      <td>81803</td>\n",
       "      <td>6602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StarTrekII.txt</th>\n",
       "      <td>22065</td>\n",
       "      <td>3673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winnie_the_Pooh_AA_Milne.txt</th>\n",
       "      <td>29936</td>\n",
       "      <td>2459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 tokens  types\n",
       "Meditations_Marcus_Aurelius.txt   81803   6602\n",
       "StarTrekII.txt                    22065   3673\n",
       "Winnie_the_Pooh_AA_Milne.txt      29936   2459"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(filesInfo, orient='index')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f4f7b41-9f43-4aa4-9016-79ad524fb626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>types</th>\n",
       "      <th>lex_div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Meditations_Marcus_Aurelius.txt</th>\n",
       "      <td>81803</td>\n",
       "      <td>6602</td>\n",
       "      <td>0.080706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StarTrekII.txt</th>\n",
       "      <td>22065</td>\n",
       "      <td>3673</td>\n",
       "      <td>0.166463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winnie_the_Pooh_AA_Milne.txt</th>\n",
       "      <td>29936</td>\n",
       "      <td>2459</td>\n",
       "      <td>0.082142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 tokens  types   lex_div\n",
       "Meditations_Marcus_Aurelius.txt   81803   6602  0.080706\n",
       "StarTrekII.txt                    22065   3673  0.166463\n",
       "Winnie_the_Pooh_AA_Milne.txt      29936   2459  0.082142"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lex_div'] = df['types']/df['tokens']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe498cc1-0d06-4a92-8663-c657ccf92435",
   "metadata": {},
   "source": [
    "### **The top 10 most frequent words and their counts:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "afb4a6a8-62b7-4d27-85e9-d4e3d6eaf198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    #removes unwanted punctuation from text\n",
    "    text_clean = re.sub(r'[\\,\\.\\\"\\”\\“\\*\\)\\(\\-\\!\\?]', '', text,)\n",
    "    return text_clean\n",
    "\n",
    "path = './data'\n",
    "word_freq = {}\n",
    "    #reads and processes files to be cleaned and counted\n",
    "for filename in os.listdir(path):\n",
    "        if filename.endswith(\".txt\"):    \n",
    "            file_path = os.path.join(path, filename)      \n",
    "            with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "                text = text_cleaner(f.read())\n",
    "                tokens = word_tokenize(text)\n",
    "                word_freq[filename] = FreqDist(tokens).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38875750-e070-4e3b-a00e-d8125a77d194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meditations_Marcus_Aurelius.txt: [('and', 3049), ('the', 2400), ('of', 2281), ('to', 1916), ('that', 1882), ('is', 1394), ('it', 1118), ('in', 1060), ('a', 993), ('be', 963)]\n",
      "\n",
      "StarTrekII.txt: [('the', 564), ('to', 354), ('KIRK', 271), ('and', 263), ('a', 233), ('of', 227), ('I', 206), ('is', 203), ('you', 191), (\"'s\", 172)]\n",
      "\n",
      "Winnie_the_Pooh_AA_Milne.txt: [('and', 792), ('the', 652), ('he', 576), ('said', 539), ('to', 537), ('a', 502), ('it', 479), ('I', 453), ('of', 377), ('Pooh', 351)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(f\"\\n{filename}: {words}\" for filename, words in word_freq.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86803c24-012e-4ffc-b825-293c6b987e97",
   "metadata": {},
   "source": [
    "### **Named Entities:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d73cccf6-def5-4145-8de2-0d107c725fbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for Meditations_Marcus_Aurelius.txt:\n",
      "                                      entity   label\n",
      "0     NTH BOOK\\n\\n     TWELFTH BOOK\\n\\n          ORG\n",
      "1                  MARCUS AURELIUS ANTONINUS     ORG\n",
      "2                                   April 26    DATE\n",
      "3                                   A.D. 121    DATE\n",
      "4                            M. Annius Verus     ORG\n",
      "...                                      ...     ...\n",
      "1496                                   Roman    NORP\n",
      "1497                                   Roman     ORG\n",
      "1498                                  Marcus     ORG\n",
      "1499                                  Fronto  PERSON\n",
      "1500                                  Fronto     ORG\n",
      "\n",
      "[1501 rows x 2 columns]\n",
      "\n",
      "\n",
      "DataFrame for StarTrekII.txt:\n",
      "               entity     label\n",
      "0                KHAN    PERSON\n",
      "1     Jack B. Sowards    PERSON\n",
      "2               Story    PERSON\n",
      "3       Harve Bennett    PERSON\n",
      "4     Jack B. Sowards    PERSON\n",
      "...               ...       ...\n",
      "2567              274  CARDINAL\n",
      "2568              274  CARDINAL\n",
      "2569            SPOCK       ORG\n",
      "2570             VIEW       ORG\n",
      "2571              END       ORG\n",
      "\n",
      "[2572 rows x 2 columns]\n",
      "\n",
      "\n",
      "DataFrame for Winnie_the_Pooh_AA_Milne.txt:\n",
      "                     entity     label\n",
      "0     A. EDWARD\\n    NEWTON    PERSON\n",
      "1      The Atlantic Monthly       LOC\n",
      "2                  Fourteen  CARDINAL\n",
      "3               A. A. Milne    PERSON\n",
      "4          H. Fraser-Simson    PERSON\n",
      "...                     ...       ...\n",
      "1593                  Kanga       GPE\n",
      "1594                    Roo    PERSON\n",
      "1595                 Eeyore    PERSON\n",
      "1596                   Pooh    PERSON\n",
      "1597                   Pooh    PERSON\n",
      "\n",
      "[1598 rows x 2 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ent_dfs = {}\n",
    "\n",
    "path = './data'\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "        if filename.endswith(\".txt\"):    \n",
    "            file_path = os.path.join(path, filename)      \n",
    "            with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "                doc = nlp(text)\n",
    "\n",
    "            named_ents = []            \n",
    "\n",
    "            # go through the entities and append each to the list\n",
    "            for ent in doc.ents:\n",
    "                named_ents.append((ent.text, ent.label_))\n",
    "\n",
    "            df = pd.DataFrame(named_ents, columns=['entity', 'label'])\n",
    "\n",
    "            ent_dfs[filename] = df\n",
    "            \n",
    "for filename, df in ent_dfs.items():\n",
    "    print(f\"DataFrame for {filename}:\")\n",
    "    print(df)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa3789f-0a9f-41cd-8c04-a1d953cdff1d",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "&emsp;Our dataset is comprised of a screenplay from 1982, _Star Trek II_; a children’s novel from 1926, _The Adventures of Winnie the Pooh_; and a 2000-year-old book originally written in Koine Greek, _Meditations_. \n",
    "<br>\n",
    "&emsp;Notably, across all genres the most frequent words in the text are function words. These are words that contain little lexical meaning but facilitate the meaning of a phrase. It makes sense that these are most common, as they are present in almost all sentences, regardless of genre or medium. The only other type of word that appeared on this list is character names. These only appeared in Winnie the Pooh and Star Trek which is unsurprising as these are both narratives while Meditations is more of a journal containing the author's musings and therefore there are not names mentioned often enough to appear in the top 10 list. Similarly, in the Named Entities section, the narratives had a higher prevalence of Names in the output than Meditations did. Additionally, more errors seemed to have been made with this file. This could be due to the year it was published as language has changed significantly since that time. For example, the output suggests that the authors name, Marcus Aurelius Antoninus, as an organisation. This could however be explained by the fact that a name like this would no longer be common and therefore might not match patterns from the database.  In truth, all genres have mistakes in the named entities, even when so few examples are given in the output. One error that occurred multiple times is the same token being categorised as two different entities. This shows that while this function can have major benefits, results must be thought about critically before this data can be used.\n",
    "<br>\n",
    "&emsp;Star Trek was the most lexically diverse file with a score of 0.167. Winnie the Pooh and Meditations  had a very similar score of 0.081 and 0.082 respectively. This difference may come down to the genre. Star Trek is a screenplay meaning that every utterance is likely more or less unique without the need for all the “she/he/they said” and other repetitive descriptors used to describe a scene.  The place where a screenplay would likely have a fair bit of repetition would be in the names which are used to show who’s speaking. This is evidenced in “KIRK” being the third most frequent token in the Star Trek screenplay. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
