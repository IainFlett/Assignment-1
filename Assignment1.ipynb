{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b16e735c-c570-4ac0-ac6d-37877e705b3c",
   "metadata": {},
   "source": [
    "|  Name | Student ID | Section Contributed | Section Edited | Other Contributions |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Dueck, Ellie | 301462367 | \n",
    "| Flett, Iain | 301581520 | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87c3494f-f1e2-498a-a42e-024bcf5517a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import numpy\n",
    "import re\n",
    "import matplotlib\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import FreqDist\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b34737f8-66ca-4f70-8d0a-02beb497e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_info(text):\n",
    "    \"\"\"\n",
    "    Uses NLTK to calculate: tokens, types, lexical diversity\n",
    "    \n",
    "    Args:\n",
    "        text (str): a string containing the file or text\n",
    "        \n",
    "    Returns: \n",
    "        dict: a dictionary containing tokens, types, and lexical diversity\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    n_tokens = len(tokens)\n",
    "    n_types = len(set(tokens))\n",
    "    return {\n",
    "            'tokens': n_tokens,\n",
    "            'types': n_types,\n",
    "        }\n",
    "def process_dir(path):\n",
    "    \"\"\"\n",
    "    Reads all the files in a directory. Processes them using the 'get_text_info' function\n",
    "    \n",
    "    Args: \n",
    "        path (str): path to the directory where the files are\n",
    "        \n",
    "    Returns:\n",
    "        dict: a dictionary with file names as keys and the tokens, types, lexical diversity, as values\n",
    "    \n",
    "    \"\"\"\n",
    "    file_info = {}\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".txt\"):    \n",
    "            file_path = os.path.join(path, filename)      \n",
    "            with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "                file_info[filename] = get_text_info(text)\n",
    "    return file_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2de5c49d-015b-40e0-a4e5-73d90e457def",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data'\n",
    "\n",
    "filesInfo = process_dir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b1b0580-f712-4d1f-991e-2e1e92dd4f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Meditations_Marcus_Aurelius.txt</th>\n",
       "      <td>81803</td>\n",
       "      <td>6602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StarTrekII.txt</th>\n",
       "      <td>22065</td>\n",
       "      <td>3673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winnie_the_Pooh_AA_Milne.txt</th>\n",
       "      <td>30602</td>\n",
       "      <td>2650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 tokens  types\n",
       "Meditations_Marcus_Aurelius.txt   81803   6602\n",
       "StarTrekII.txt                    22065   3673\n",
       "Winnie_the_Pooh_AA_Milne.txt      30602   2650"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(filesInfo, orient='index')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f4f7b41-9f43-4aa4-9016-79ad524fb626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>types</th>\n",
       "      <th>lex_div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Meditations_Marcus_Aurelius.txt</th>\n",
       "      <td>81803</td>\n",
       "      <td>6602</td>\n",
       "      <td>0.080706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StarTrekII.txt</th>\n",
       "      <td>22065</td>\n",
       "      <td>3673</td>\n",
       "      <td>0.166463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winnie_the_Pooh_AA_Milne.txt</th>\n",
       "      <td>30602</td>\n",
       "      <td>2650</td>\n",
       "      <td>0.086596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 tokens  types   lex_div\n",
       "Meditations_Marcus_Aurelius.txt   81803   6602  0.080706\n",
       "StarTrekII.txt                    22065   3673  0.166463\n",
       "Winnie_the_Pooh_AA_Milne.txt      30602   2650  0.086596"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lex_div'] = df['types']/df['tokens']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe498cc1-0d06-4a92-8663-c657ccf92435",
   "metadata": {},
   "source": [
    "The top 10 most frequent words and their counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "afb4a6a8-62b7-4d27-85e9-d4e3d6eaf198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    #removes unwanted punctuation\n",
    "    text_clean = re.sub(r'[\\,\\.\\\"\\”\\“\\*]', '', text,)\n",
    "    return text_clean\n",
    "\n",
    "path = './data'\n",
    "file_info = {}\n",
    "    #reads and processes files to be cleaned and counted\n",
    "for filename in os.listdir(path):\n",
    "        if filename.endswith(\".txt\"):    \n",
    "            file_path = os.path.join(path, filename)      \n",
    "            with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "                file_info[filename] = text_cleaner(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "38875750-e070-4e3b-a00e-d8125a77d194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 829),\n",
       " ('the', 678),\n",
       " ('he', 578),\n",
       " ('to', 555),\n",
       " ('said', 540),\n",
       " ('a', 517),\n",
       " ('it', 483),\n",
       " ('I', 459),\n",
       " ('of', 396),\n",
       " ('Pooh', 351)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clean = text_cleaner(text)\n",
    "text_tokens=word_tokenize(text_clean)\n",
    "freq_dist = FreqDist(text_tokens)\n",
    "freq_dist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c70a50-210f-42b9-8aa6-443a016081ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
